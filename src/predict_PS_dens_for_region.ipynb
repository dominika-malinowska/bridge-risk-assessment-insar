{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885156f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script can be used to predict the pixel-wise density of\n",
    "the PS points for a given region. It uses a trained model and\n",
    "the input data consists of long-term coherence that can be downloaded\n",
    "by the script and infrastructure map thats generated by processing\n",
    "an OSM file that has to be already downloaded.\n",
    "The script generates prediction chips and saves them\n",
    "as a geotiff file.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf3f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Python version (3.9 needed)\n",
    "# !python --version # jupyter\n",
    "# import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a87fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72f8c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from torchgeo.datasets import (\n",
    "    stack_samples,\n",
    ")\n",
    "from torchgeo.samplers import GridGeoSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499dac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ps_predictions.utils.torchgeo_classes_def import PixelwiseRegressionTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ps_predictions.utils.torchgeo_fun_to_read_input import (\n",
    "    scale_coh,\n",
    "    RasterDataset_imgs,\n",
    ")\n",
    "from ps_predictions.utils.prediction_plots import (\n",
    "    georreferenced_chip_generator,\n",
    "    merge_georeferenced_chips,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccdf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ps_predictions.infrastructure_map_generation import generate_infrastructure_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c174d",
   "metadata": {},
   "source": [
    "print(f\"Python version {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e1db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if torch with cuda enabled and working\n",
    "# torch.zeros(1).cuda()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9321901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warning about number of warnings\n",
    "# See https://github.com/Lightning-AI/lightning/issues/10182\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions #\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    This function calculates the haversine distance between two points on the Earth's surface.\n",
    "\n",
    "    Arguments:\n",
    "        lat1 (float): Latitude of the first point in degrees\n",
    "        lon1 (float): Longitude of the first point in degrees\n",
    "        lat2 (float): Latitude of the second point in degrees\n",
    "        lon2 (float): Longitude of the second point in degrees\n",
    "\n",
    "    Returns:\n",
    "        float: The haversine distance between the two points in kilometers\n",
    "    \"\"\"\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    a = (\n",
    "        math.sin(dlat / 2) ** 2\n",
    "        + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2) ** 2\n",
    "    )\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc52f5",
   "metadata": {},
   "source": [
    "Set-up region to be analysed #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af0335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! FOR NOW IT ONLY WORKS IF THE REGION IS WITHIN ONE BY ONE DEGREE TILE (TO BE UPDATED) !!!\n",
    "x = [18.53, 18.9]\n",
    "y = [50.05, 50.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fec8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances\n",
    "lat_distance = haversine_distance(y[0], x[0], y[1], x[0])\n",
    "lon_distance = haversine_distance(y[0], x[0], y[0], x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0a5d9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Calculate area in square kilometers\n",
    "area_km2 = lat_distance * lon_distance\n",
    "print(f\"Area: {area_km2:.2f} kmÂ²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7b0f8",
   "metadata": {},
   "source": [
    "Set-up variables #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/mnt/d/ML_model_data_paper/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7874bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for saving results (such as model checkpoints)\n",
    "path_prefix = os.path.join(root + \"testing_new_strucutre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"testing_new_strucutre\"\n",
    "experiment_dir = os.path.join(path_prefix, experiment_name)\n",
    "# print(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5cc137",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(experiment_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37904a9f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define the path for the clipped O5M file\n",
    "clipped_osm_pbf = os.path.join(experiment_dir, \"slaskie-latest.osm.pbf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1442595",
   "metadata": {},
   "source": [
    "Set-up model parameters #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab9977",
   "metadata": {},
   "source": [
    "# Constant parameters\n",
    "in_channels = 2  # Number of channels in input image\n",
    "ignore_index = None  # Optional integer class index to ignore in the loss and metrics\n",
    "lr_patience = 10  # Patience for learning rate scheduler\n",
    "min_delta_lr = 0.01\n",
    "patience = 15  # Patience for early stopping\n",
    "min_delta = (\n",
    "    0.01  # when change in val_loss less than that for appropriate number of epochs\n",
    ")\n",
    "# early stopping will be triggered\n",
    "max_epochs = 300  # maximum number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff39caeb",
   "metadata": {},
   "source": [
    "gpu_id = 0\n",
    "device = torch.device(f\"cuda:{gpu_id}\")\n",
    "num_dataloader_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98197744",
   "metadata": {},
   "source": [
    "param_const = [\n",
    "    in_channels,\n",
    "    ignore_index,\n",
    "    lr_patience,\n",
    "    min_delta_lr,\n",
    "    patience,\n",
    "    min_delta,\n",
    "    max_epochs,\n",
    "    gpu_id,\n",
    "    device,\n",
    "    num_dataloader_workers,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d3d7e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Modifiable parameters\n",
    "param_opts = [\n",
    "    [16, 64, None, \"resnet34\", None, \"mae\", 0.00776601, 0.9, 0.99, 0.01],\n",
    "]\n",
    "patch_size = param_opts[0][1]\n",
    "batch_size = param_opts[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the patch size and batch size for the model\n",
    "patch_size = 64\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select overlap parameter for merging patches in prediction\n",
    "overlap = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac9181",
   "metadata": {},
   "source": [
    "Read trained model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bbfc8d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Read trained model\n",
    "model = PixelwiseRegressionTask.load_from_checkpoint(\n",
    "    checkpoint_path=os.path.join(\n",
    "        root, \"best_models_15122023\", \"seed_54321_20231214-203338.ckpt\"\n",
    "    )\n",
    ")\n",
    "plots_folder_name = \"tests_new_structure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507db56",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Set-up seed\n",
    "seed = 54321\n",
    "seed_everything(seed, workers=True)\n",
    "generator = torch.Generator().manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08771bd1",
   "metadata": {},
   "source": [
    "Apply model to unseen data #\n",
    "tags_high = {\"highway\": [\"motorway\", \"trunk\", \"primary\", \"secondary\"]}\n",
    "tags_build = {\"building\": [\"yes\"]}\n",
    "tags_rail = {\"railway\": [\"rail\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x = min(x)\n",
    "min_y = min(y)\n",
    "max_x = max(x)\n",
    "max_y = max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01fa886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert min_x and min_y to integers for use in formatting the latitude and longitude\n",
    "west = math.floor(min_x)\n",
    "south = math.floor(min_y)\n",
    "east = math.ceil(max_x)\n",
    "north = math.ceil(max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert min_x and min_y to integers for use in formatting the latitude and longitude\n",
    "lon = int(min_x)\n",
    "lat = int(min_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6274ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the latitude and determine the season based on whether the latitude is positive or negative\n",
    "if south >= 0:\n",
    "    lat_f = \"N{:02d}\".format(south + 1)\n",
    "    season = \"summer\"\n",
    "else:\n",
    "    lat_f = \"S{:02d}\".format(abs(south + 1))\n",
    "    season = \"winter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29085b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the longitude based on whether it is positive or negative\n",
    "if west >= 0:\n",
    "    lon_f = \"E{:03d}\".format(west)\n",
    "else:\n",
    "    lon_f = \"W{:03d}\".format(abs(west))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6dc1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the currently processed tile's coordinates\n",
    "print(\n",
    "    \"Currently processed tile lat:{},{} lon:{},{}\".format(min_y, max_y, min_x, max_x),\n",
    "    flush=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d3bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bounds for the prediction tile\n",
    "bounds = (min_x, min_y, max_x, max_y)\n",
    "bounds_name = (int(min_x), int(min_y), int(max_x), int(max_y))\n",
    "bounds_ltcoh = (\n",
    "    math.floor(min_x),\n",
    "    math.floor(min_y),\n",
    "    math.ceil(max_x),\n",
    "    math.ceil(max_y),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_time_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the PS prediction raster\n",
    "file_name = os.path.join(\n",
    "    experiment_dir, \"{}{}\".format(lat_f, lon_f), \"{}{}_PS_pred.tif\".format(lat_f, lon_f)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967d2c4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Check if prediction exists already\n",
    "if os.path.exists(file_name):\n",
    "    print(\"PS is already predicted for tile {}{} \\n\".format(lat_f, lon_f), flush=True)\n",
    "    sys.exit()  # Stop the execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c82b3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# If the prediction does not exist, start the prediction process\n",
    "# Create the directory for storing outputs if it doesn't exist\n",
    "dir_coord = os.path.join(experiment_dir, \"{}{}\".format(lat_f, lon_f))\n",
    "if not os.path.exists(dir_coord):\n",
    "    os.makedirs(dir_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4f076",
   "metadata": {},
   "source": [
    "Infrastructure map #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory for the infrastructure map raster\n",
    "infrmap_raster_dir = os.path.join(\n",
    "    experiment_dir,\n",
    "    \"{}{}\".format(lat_f, lon_f),\n",
    "    \"infr_map\",\n",
    "    \"{}{}_infrs_map.tif\".format(lat_f, lon_f),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the infrastructure map already exists\n",
    "if os.path.exists(infrmap_raster_dir):\n",
    "    print(\n",
    "        \"Infrastructure map {}{} is already generated.\".format(lat_f, lon_f),\n",
    "        flush=True,\n",
    "    )\n",
    "# If the infrastructure map does not exist, start the generation process\n",
    "else:\n",
    "    generate_infrastructure_map(\n",
    "        lat_f,\n",
    "        lon_f,\n",
    "        min_x,\n",
    "        min_y,\n",
    "        max_x,\n",
    "        max_y,\n",
    "        experiment_dir,\n",
    "        clipped_osm_pbf,\n",
    "        infrmap_raster_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2b8ed5",
   "metadata": {},
   "source": [
    "Long-term coherence #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850433b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of long-term coherence section\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc182520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the long-term coherence tile\n",
    "coh_tile_path = \"{coh_dir}/{lat}{lon}/coh/{lat}{lon}_{season}_vv_rho.tif\".format(\n",
    "    lat=lat_f, lon=lon_f, season=season, coh_dir=experiment_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ccdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the long-term coherence tile already exists\n",
    "# If not, try to download it\n",
    "if os.path.exists(coh_tile_path):\n",
    "    print(\n",
    "        \"Long-term coherence tile  {}{} is already downloaded.\".format(lat_f, lon_f),\n",
    "        flush=True,\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"\\n Long-term coherence tile {}{} is missing! Trying to download \\n\".format(\n",
    "            lat_f, lon_f\n",
    "        ),\n",
    "        flush=True,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        os.system(\n",
    "            f\"aws s3 cp s3://sentinel-1-global-coherence-earthbigdata/data/tiles/{lat_f}{lon_f}/\"\n",
    "            f\"{lat_f}{lon_f}_{season}_vv_rho.tif --no-sign-request \"\n",
    "            f\"{experiment_dir}/{lat_f}{lon_f}/coh/{lat_f}{lon_f}_{season}_vv_rho.tif\"\n",
    "        )\n",
    "\n",
    "        if os.path.exists(\n",
    "            \"{coh_dir}/{lat}{lon}/coh/{lat}{lon}_{season}_vv_rho.tif\".format(\n",
    "                lat=lat_f, lon=lon_f, season=season, coh_dir=experiment_dir\n",
    "            )\n",
    "        ):\n",
    "            print(\"Download of {}{} tiles ended.\".format(lat_f, lon_f))\n",
    "        else:\n",
    "            print(\"\\n Download of tile {}{} failed. \\n\".format(lat_f, lon_f))\n",
    "\n",
    "    except BaseException as error:\n",
    "        print(\n",
    "            \"There is a problem with the download of the file. Please see following line to identify the error.\"\n",
    "        )\n",
    "        print(\"An exception occurred: {}\".format(error))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An exception occurred: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d0228",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Calculate the total execution time for checking the long-term coherence file\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(\n",
    "    f\"Total execution time for downloading the long term cohrence file: {total_time:.2f} seconds\",\n",
    "    flush=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f933f9e",
   "metadata": {},
   "source": [
    "Prepare input data for the model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adeecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RasterDataset objects for coherence and infrastructure map images\n",
    "imgs_coh = RasterDataset_imgs(\n",
    "    paths=os.path.join(\n",
    "        experiment_dir,\n",
    "        \"{}{}\".format(lat_f, lon_f),\n",
    "        \"coh\",\n",
    "    ),\n",
    "    transforms=scale_coh,\n",
    ")\n",
    "imgs_infrmap = RasterDataset_imgs(\n",
    "    paths=os.path.join(experiment_dir, \"{}{}\".format(lat_f, lon_f), \"infr_map\")\n",
    ")\n",
    "# Combine the two RasterDataset objects\n",
    "imgs_input = imgs_coh & imgs_infrmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3670c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataset to predict\n",
    "dataset_to_pred = imgs_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GridGeoSampler object for the dataset\n",
    "sampler_pred = GridGeoSampler(dataset_to_pred, patch_size, patch_size - overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4de09",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create dataloader\n",
    "dataloader_interf = DataLoader(\n",
    "    dataset=dataset_to_pred,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler_pred,\n",
    "    num_workers=0,\n",
    "    collate_fn=stack_samples,\n",
    "    generator=generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0b2c6",
   "metadata": {},
   "source": [
    "Run predictions #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction chips\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate geotiff\n",
    "# Get the pixel size and CRS of the dataset\n",
    "pixel_size = dataset_to_pred.res\n",
    "crs = dataset_to_pred.crs.to_epsg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction chips\n",
    "start = time.time()  # Start measuring the time\n",
    "chips_generator = georreferenced_chip_generator(\n",
    "    dataloader_interf, model, crs, pixel_size\n",
    ")\n",
    "print(\"The time taken to predict was: \", time.time() - start, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae23a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the prediction chips as a geotiff\n",
    "start = time.time()  # Start measuring the time\n",
    "merge_georeferenced_chips(chips_generator, file_name, overlap, bounds)\n",
    "print(\n",
    "    \"The time taken to generate a georrefenced image and save it was: \",\n",
    "    time.time() - start,\n",
    "    flush=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28127d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total execution time for processing one tile\n",
    "tile_time_end = time.time()\n",
    "tile_time = tile_time_end - tile_time_start\n",
    "print(f\"Time for processing one tile: {tile_time:.2f} seconds\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
